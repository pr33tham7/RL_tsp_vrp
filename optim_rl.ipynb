{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6475985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db9619fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09c98831",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Defines the main trainer model for combinatorial problems\n",
    "\n",
    "Each task must define the following functions:\n",
    "* mask_fn: can be None\n",
    "* update_fn: can be None\n",
    "* reward_fn: specifies the quality of found solutions\n",
    "* render_fn: Specifies how to plot found solutions. Can be None\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model import DRL4TSP, Encoder\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "\n",
    "\n",
    "class StateCritic(nn.Module):\n",
    "    \"\"\"Estimates the problem complexity.\n",
    "\n",
    "    This is a basic module that just looks at the log-probabilities predicted by\n",
    "    the encoder + decoder, and returns an estimate of complexity\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, static_size, dynamic_size, hidden_size):\n",
    "        super(StateCritic, self).__init__()\n",
    "\n",
    "        self.static_encoder = Encoder(static_size, hidden_size)\n",
    "        self.dynamic_encoder = Encoder(dynamic_size, hidden_size)\n",
    "\n",
    "        # Define the encoder & decoder models\n",
    "        self.fc1 = nn.Conv1d(hidden_size * 2, 20, kernel_size=1)\n",
    "        self.fc2 = nn.Conv1d(20, 20, kernel_size=1)\n",
    "        self.fc3 = nn.Conv1d(20, 1, kernel_size=1)\n",
    "\n",
    "        for p in self.parameters():\n",
    "            if len(p.shape) > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, static, dynamic):\n",
    "\n",
    "        # Use the probabilities of visiting each\n",
    "        static_hidden = self.static_encoder(static)\n",
    "        dynamic_hidden = self.dynamic_encoder(dynamic)\n",
    "\n",
    "        hidden = torch.cat((static_hidden, dynamic_hidden), 1)\n",
    "\n",
    "        output = F.relu(self.fc1(hidden))\n",
    "        output = F.relu(self.fc2(output))\n",
    "        output = self.fc3(output).sum(dim=2)\n",
    "        return output\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    \"\"\"Estimates the problem complexity.\n",
    "\n",
    "    This is a basic module that just looks at the log-probabilities predicted by\n",
    "    the encoder + decoder, and returns an estimate of complexity\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Critic, self).__init__()\n",
    "\n",
    "        # Define the encoder & decoder models\n",
    "        self.fc1 = nn.Conv1d(1, hidden_size, kernel_size=1)\n",
    "        self.fc2 = nn.Conv1d(hidden_size, 20, kernel_size=1)\n",
    "        self.fc3 = nn.Conv1d(20, 1, kernel_size=1)\n",
    "\n",
    "        for p in self.parameters():\n",
    "            if len(p.shape) > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        output = F.relu(self.fc1(input.unsqueeze(1)))\n",
    "        output = F.relu(self.fc2(output)).squeeze(2)\n",
    "        output = self.fc3(output).sum(dim=2)\n",
    "        return output\n",
    "\n",
    "\n",
    "def validate(data_loader, actor, reward_fn, render_fn=None, save_dir='.',\n",
    "             num_plot=5):\n",
    "    \"\"\"Used to monitor progress on a validation set & optionally plot solution.\"\"\"\n",
    "\n",
    "    actor.eval()\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    rewards = []\n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "\n",
    "        static, dynamic, x0 = batch\n",
    "\n",
    "        static = static.to(device)\n",
    "        dynamic = dynamic.to(device)\n",
    "        x0 = x0.to(device) if len(x0) > 0 else None\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tour_indices, _ = actor.forward(static, dynamic, x0)\n",
    "\n",
    "        reward = reward_fn(static, tour_indices).mean().item()\n",
    "        rewards.append(reward)\n",
    "\n",
    "        if render_fn is not None and batch_idx < num_plot:\n",
    "            name = 'batch%d_%2.4f.png'%(batch_idx, reward)\n",
    "            path = os.path.join(save_dir, name)\n",
    "            render_fn(static, tour_indices, path)\n",
    "\n",
    "    actor.train()\n",
    "    return np.mean(rewards)\n",
    "\n",
    "\n",
    "def train(actor, critic, task, num_nodes, train_data, valid_data, reward_fn,\n",
    "          render_fn, batch_size, actor_lr, critic_lr, max_grad_norm,\n",
    "          **kwargs):\n",
    "    \"\"\"Constructs the main actor & critic networks, and performs all training.\"\"\"\n",
    "\n",
    "    now = '%s' % datetime.datetime.now().time()\n",
    "    now = now.replace(':', '_')\n",
    "    save_dir = os.path.join(task, '%d' % num_nodes, now)\n",
    "\n",
    "    checkpoint_dir = os.path.join(save_dir, 'checkpoints')\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "    actor_optim = optim.Adam(actor.parameters(), lr=actor_lr)\n",
    "    critic_optim = optim.Adam(critic.parameters(), lr=critic_lr)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size, True, num_workers=0)\n",
    "    valid_loader = DataLoader(valid_data, batch_size, False, num_workers=0)\n",
    "\n",
    "    best_params = None\n",
    "    best_reward = np.inf\n",
    "\n",
    "    for epoch in range(20):\n",
    "\n",
    "        actor.train()\n",
    "        critic.train()\n",
    "\n",
    "        times, losses, rewards, critic_rewards = [], [], [], []\n",
    "\n",
    "        epoch_start = time.time()\n",
    "        start = epoch_start\n",
    "\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "\n",
    "            static, dynamic, x0 = batch\n",
    "\n",
    "            static = static.to(device)\n",
    "            dynamic = dynamic.to(device)\n",
    "            x0 = x0.to(device) if len(x0) > 0 else None\n",
    "\n",
    "            # Full forward pass through the dataset\n",
    "            tour_indices, tour_logp = actor(static, dynamic, x0)\n",
    "\n",
    "            # Sum the log probabilities for each city in the tour\n",
    "            reward = reward_fn(static, tour_indices)\n",
    "\n",
    "            # Query the critic for an estimate of the reward\n",
    "            critic_est = critic(static, dynamic).view(-1)\n",
    "\n",
    "            advantage = (reward - critic_est)\n",
    "            actor_loss = torch.mean(advantage.detach() * tour_logp.sum(dim=1))\n",
    "            critic_loss = torch.mean(advantage ** 2)\n",
    "\n",
    "            actor_optim.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(actor.parameters(), max_grad_norm)\n",
    "            actor_optim.step()\n",
    "\n",
    "            critic_optim.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(critic.parameters(), max_grad_norm)\n",
    "            critic_optim.step()\n",
    "\n",
    "            critic_rewards.append(torch.mean(critic_est.detach()).item())\n",
    "            rewards.append(torch.mean(reward.detach()).item())\n",
    "            losses.append(torch.mean(actor_loss.detach()).item())\n",
    "\n",
    "            if (batch_idx + 1) % 100 == 0:\n",
    "                end = time.time()\n",
    "                times.append(end - start)\n",
    "                start = end\n",
    "\n",
    "                mean_loss = np.mean(losses[-100:])\n",
    "                mean_reward = np.mean(rewards[-100:])\n",
    "\n",
    "                print('  Batch %d/%d, reward: %2.3f, loss: %2.4f, took: %2.4fs' %\n",
    "                      (batch_idx, len(train_loader), mean_reward, mean_loss,\n",
    "                       times[-1]))\n",
    "\n",
    "        mean_loss = np.mean(losses)\n",
    "        mean_reward = np.mean(rewards)\n",
    "\n",
    "        # Save the weights\n",
    "        epoch_dir = os.path.join(checkpoint_dir, '%s' % epoch)\n",
    "        if not os.path.exists(epoch_dir):\n",
    "            os.makedirs(epoch_dir)\n",
    "\n",
    "        save_path = os.path.join(epoch_dir, 'actor.pt')\n",
    "        torch.save(actor.state_dict(), save_path)\n",
    "\n",
    "        save_path = os.path.join(epoch_dir, 'critic.pt')\n",
    "        torch.save(critic.state_dict(), save_path)\n",
    "\n",
    "        # Save rendering of validation set tours\n",
    "        valid_dir = os.path.join(save_dir, '%s' % epoch)\n",
    "\n",
    "        mean_valid = validate(valid_loader, actor, reward_fn, render_fn,\n",
    "                              valid_dir, num_plot=5)\n",
    "\n",
    "        # Save best model parameters\n",
    "        if mean_valid < best_reward:\n",
    "\n",
    "            best_reward = mean_valid\n",
    "\n",
    "            save_path = os.path.join(save_dir, 'actor.pt')\n",
    "            torch.save(actor.state_dict(), save_path)\n",
    "\n",
    "            save_path = os.path.join(save_dir, 'critic.pt')\n",
    "            torch.save(critic.state_dict(), save_path)\n",
    "\n",
    "        print('Mean epoch loss/reward: %2.4f, %2.4f, %2.4f, took: %2.4fs '\\\n",
    "              '(%2.4fs / 100 batches)\\n' % \\\n",
    "              (mean_loss, mean_reward, mean_valid, time.time() - epoch_start,\n",
    "              np.mean(times)))\n",
    "\n",
    "\n",
    "\n",
    "def train_tsp():#args\n",
    "\n",
    "    # Goals from paper:\n",
    "    # TSP20, 3.97\n",
    "    # TSP50, 6.08\n",
    "    # TSP100, 8.44\n",
    "\n",
    "    from tasks import tsp\n",
    "    from tasks.tsp import TSPDataset\n",
    "\n",
    "    STATIC_SIZE = 2 # (x, y)\n",
    "    DYNAMIC_SIZE = 1 # dummy for compatibility\n",
    "    \n",
    "    \n",
    "#  parser = argparse.ArgumentParser(description='Combinatorial Optimization')\n",
    "#     parser.add_argument('--seed', default=12345, type=int)\n",
    "#     parser.add_argument('--checkpoint', default=None)\n",
    "#     parser.add_argument('--test', action='store_true', default=False)\n",
    "#     parser.add_argument('--task', default='tsp')\n",
    "#     parser.add_argument('--nodes', dest='num_nodes', default=20, type=int)\n",
    "#     parser.add_argument('--actor_lr', default=5e-4, type=float)\n",
    "#     parser.add_argument('--critic_lr', default=5e-4, type=float)\n",
    "#     parser.add_argument('--max_grad_norm', default=2., type=float)\n",
    "#     parser.add_argument('--batch_size', default=256, type=int)\n",
    "#     parser.add_argument('--hidden', dest='hidden_size', default=128, type=int)\n",
    "#     parser.add_argument('--dropout', default=0.1, type=float)\n",
    "#     parser.add_argument('--layers', dest='num_layers', default=1, type=int)\n",
    "#     parser.add_argument('--train-size',default=1000000, type=int)\n",
    "#     parser.add_argument('--valid-size', default=1000, type=int)\n",
    "    \n",
    "    \n",
    "    num_nodes = 20\n",
    "    train_size = 1000000\n",
    "    seed = 12345\n",
    "    valid_size = 1000\n",
    "    hidden_size = 128\n",
    "    num_layers = 100\n",
    "    checkpoint = None\n",
    "    dropout = 0.1\n",
    "    batch_size = 256\n",
    "    test = 'store_true'\n",
    "    \n",
    "    \n",
    "    train_data = TSPDataset(num_nodes, train_size, seed)\n",
    "    valid_data = TSPDataset(num_nodes, valid_size, seed + 1)\n",
    "\n",
    "    update_fn = None\n",
    "\n",
    "    actor = DRL4TSP(STATIC_SIZE,\n",
    "                    DYNAMIC_SIZE,\n",
    "                    hidden_size,\n",
    "                    update_fn,\n",
    "                    tsp.update_mask,\n",
    "                    num_layers,\n",
    "                    dropout)#.to(device)\n",
    "\n",
    "    critic = StateCritic(STATIC_SIZE, DYNAMIC_SIZE, hidden_size).to(device)\n",
    "\n",
    "    kwargs = {} #vars(args)\n",
    "    kwargs['train_data'] = train_data\n",
    "    kwargs['valid_data'] = valid_data\n",
    "    kwargs['reward_fn'] = tsp.reward\n",
    "    kwargs['render_fn'] = tsp.render\n",
    "\n",
    "    if checkpoint:\n",
    "        path = os.path.join(checkpoint, 'actor.pt')\n",
    "        actor.load_state_dict(torch.load(path, device))\n",
    "\n",
    "        path = os.path.join(checkpoint, 'critic.pt')\n",
    "        critic.load_state_dict(torch.load(path, device))\n",
    "\n",
    "    if not test:\n",
    "        train(actor, critic, kwargs)\n",
    "\n",
    "    test_data = TSPDataset(num_nodes, train_size, seed + 2)\n",
    "\n",
    "    test_dir = 'test'\n",
    "    test_loader = DataLoader(test_data, batch_size, False, num_workers=0)\n",
    "    out = validate(test_loader, actor, tsp.reward, tsp.render, test_dir, num_plot=5)\n",
    "\n",
    "    print('Average tour length: ', out)\n",
    "\n",
    "\n",
    "def train_vrp(args):\n",
    "\n",
    "    # Goals from paper:\n",
    "    # VRP10, Capacity 20:  4.84  (Greedy)\n",
    "    # VRP20, Capacity 30:  6.59  (Greedy)\n",
    "    # VRP50, Capacity 40:  11.39 (Greedy)\n",
    "    # VRP100, Capacity 50: 17.23  (Greedy)\n",
    "\n",
    "    from tasks import vrp\n",
    "    from tasks.vrp import VehicleRoutingDataset\n",
    "\n",
    "    # Determines the maximum amount of load for a vehicle based on num nodes\n",
    "    LOAD_DICT = {10: 20, 20: 30, 50: 40, 100: 50}\n",
    "    MAX_DEMAND = 9\n",
    "    STATIC_SIZE = 2 # (x, y)\n",
    "    DYNAMIC_SIZE = 2 # (load, demand)\n",
    "\n",
    "    max_load = LOAD_DICT[args.num_nodes]\n",
    "\n",
    "    train_data = VehicleRoutingDataset(args.train_size,\n",
    "                                       args.num_nodes,\n",
    "                                       max_load,\n",
    "                                       MAX_DEMAND,\n",
    "                                       args.seed)\n",
    "\n",
    "    valid_data = VehicleRoutingDataset(args.valid_size,\n",
    "                                       args.num_nodes,\n",
    "                                       max_load,\n",
    "                                       MAX_DEMAND,\n",
    "                                       args.seed + 1)\n",
    "\n",
    "    actor = DRL4TSP(STATIC_SIZE,\n",
    "                    DYNAMIC_SIZE,\n",
    "                    args.hidden_size,\n",
    "                    train_data.update_dynamic,\n",
    "                    train_data.update_mask,\n",
    "                    args.num_layers,\n",
    "                    args.dropout).to(device)\n",
    "\n",
    "    critic = StateCritic(STATIC_SIZE, DYNAMIC_SIZE, args.hidden_size).to(device)\n",
    "\n",
    "    kwargs = vars(args)\n",
    "    kwargs['train_data'] = train_data\n",
    "    kwargs['valid_data'] = valid_data\n",
    "    kwargs['reward_fn'] = vrp.reward\n",
    "    kwargs['render_fn'] = vrp.render\n",
    "\n",
    "    if args.checkpoint:\n",
    "        path = os.path.join(args.checkpoint, 'actor.pt')\n",
    "        actor.load_state_dict(torch.load(path, device))\n",
    "\n",
    "        path = os.path.join(args.checkpoint, 'critic.pt')\n",
    "        critic.load_state_dict(torch.load(path, device))\n",
    "\n",
    "    if not args.test:\n",
    "        train(actor, critic, **kwargs)\n",
    "\n",
    "    test_data = VehicleRoutingDataset(args.valid_size,\n",
    "                                      args.num_nodes,\n",
    "                                      max_load,\n",
    "                                      MAX_DEMAND,\n",
    "                                      args.seed + 2)\n",
    "\n",
    "    test_dir = 'test'\n",
    "    test_loader = DataLoader(test_data, args.batch_size, False, num_workers=0)\n",
    "    out = validate(test_loader, actor, vrp.reward, vrp.render, test_dir, num_plot=5)\n",
    "\n",
    "    print('Average tour length: ', out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336c0c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "#     parser = argparse.ArgumentParser(description='Combinatorial Optimization')\n",
    "#     parser.add_argument('--seed', default=12345, type=int)\n",
    "#     parser.add_argument('--checkpoint', default=None)\n",
    "#     parser.add_argument('--test', action='store_true', default=False)\n",
    "#     parser.add_argument('--task', default='tsp')\n",
    "#     parser.add_argument('--nodes', dest='num_nodes', default=20, type=int)\n",
    "#     parser.add_argument('--actor_lr', default=5e-4, type=float)\n",
    "#     parser.add_argument('--critic_lr', default=5e-4, type=float)\n",
    "#     parser.add_argument('--max_grad_norm', default=2., type=float)\n",
    "#     parser.add_argument('--batch_size', default=256, type=int)\n",
    "#     parser.add_argument('--hidden', dest='hidden_size', default=128, type=int)\n",
    "#     parser.add_argument('--dropout', default=0.1, type=float)\n",
    "#     parser.add_argument('--layers', dest='num_layers', default=1, type=int)\n",
    "#     parser.add_argument('--train-size',default=1000000, type=int)\n",
    "#     parser.add_argument('--valid-size', default=1000, type=int)\n",
    "\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     print('NOTE: SETTTING CHECKPOINT: ')\n",
    "#     args.checkpoint = os.path.join('vrp', '10', '12_59_47.350165' + os.path.sep)\n",
    "#     print(args.checkpoint)\n",
    "    task = 'tsp' \n",
    "    if task == 'tsp':\n",
    "        train_tsp()\n",
    "    elif args.task == 'vrp':\n",
    "        train_vrp(args)\n",
    "    else:\n",
    "        raise ValueError('Task <%s> not understood'%args.task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ff1db71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArgumentParser(prog='ipykernel_launcher.py', usage=None, description='Combinatorial Optimization', formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8ef7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
